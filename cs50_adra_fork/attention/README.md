# Masked Language Model with Attention Visualization

This project is a Python script that uses a pre-trained BERT model to predict masked tokens in a sentence and visualize the attention layers of the model.

## Features

- **Masked Token Prediction**: Predict the most likely words that can replace a masked token in a given sentence.
- **Attention Visualization**: Visualize how the BERT model attends to different parts of the input sentence during the prediction process.

## Requirements

- Python 3.x
- TensorFlow
- Hugging Face Transformers
- PIL (Python Imaging Library)

You can install the required packages using the following command:

```bash
pip install tensorflow transformers pillow
